---
title: "I want to visualize my regression model predictions and confidence intervals. Guide me: 1) Use ggplot2 in R for publication-quality plots"
description: "AI model comparison: I want to visualize my regression model predictions and confidence intervals. Guide me: 1) Use ggplo..."
date: 2025-10-15
category: comparison
layout: Clean
tags:
  - Gemini
  - Grok
  - AI Comparison
author: SNEOS Community
head:
  - - meta
    - name: description
      content: "AI model comparison: I want to visualize my regression model predictions and confidence intervals. Guide me: 1) Use ggplot2 in R for publicat..."
---

<ChatComparison
  title="I want to visualize my regression model predictions and confidence intervals. Guide me: 1) Use ggplot2 in R for publication-quality plots"
  prompt="I want to visualize my regression model predictions and confidence intervals. Guide me: 1) Use ggplot2 in R for publication-quality plots"
  :responses='{"Gemini": "You\u0027re in luck! \u0060ggplot2\u0060 is exceptionally powerful for visualizing regression models and their confidence intervals, making it perfect for publication-quality plots.\n\nWe\u0027ll cover:\n1.  **Simple Linear Regression** (one predictor)\n2.  **Linear Regression with a Categorical Variable** (grouping/faceting)\n3.  **Generalizing to GLMs / More Complex Models** (using \u0060broom\u0060 for efficiency)\n4.  **Publication-Quality Enhancements**\n\nLet\u0027s start by loading the necessary libraries and preparing some data.\n\n---\n\n## 1. Setup: Libraries and Example Data\n\nWe\u0027ll use \u0060tidyverse\u0060 for \u0060ggplot2\u0060 and \u0060dplyr\u0060, and \u0060broom\u0060 for easily extracting model components (which is a game-changer for this task).\n\n\u0060\u0060\u0060R\n# Install if you haven\u0027t already\n# install.packages(c(\u0022tidyverse\u0022, \u0022broom\u0022))\n\nlibrary(tidyverse) # Includes ggplot2, dplyr, etc.\nlibrary(broom)     # For tidying model outputs\n\n# We\u0027ll use the \u0027diamonds\u0027 dataset for our examples\ndata(\u0022diamonds\u0022)\n\n# Let\u0027s simplify the diamonds dataset for clearer examples\n# and take a subset to make plotting faster on some machines\nset.seed(123) # for reproducibility\ndiamonds_sub \u003C- diamonds %\u003E%\n  sample_n(5000) %\u003E% # Take a sample\n  select(price, carat, depth, cut, color) %\u003E%\n  mutate(\n    # Convert cut and color to ordered factors for better interpretation if desired\n    cut = factor(cut, levels = c(\u0022Fair\u0022, \u0022Good\u0022, \u0022Very Good\u0022, \u0022Premium\u0022, \u0022Ideal\u0022), ordered = TRUE),\n    color = factor(color, levels = c(\u0022J\u0022, \u0022I\u0022, \u0022H\u0022, \u0022G\u0022, \u0022F\u0022, \u0022E\u0022, \u0022D\u0022), ordered = TRUE)\n  )\n\nhead(diamonds_sub)\n\u0060\u0060\u0060\n\n\u0060\u0060\u0060\n# A tibble: 6 x 5\n  price carat depth cut   color\n  \u003Cint\u003E \u003Cdbl\u003E \u003Cdbl\u003E \u003Cord\u003E \u003Cord\u003E\n1  8067  1.01  61.5 Ideal J\n2  4400  0.9   61.2 Ideal J\n3  5522  0.92  61.5 Ideal H\n4  1624  0.72  62.1 Ideal J\n5 12590  1.5   61.8 Ideal G\n6  6366  1.01  61.5 Ideal F\n\u0060\u0060\u0060\n\n---\n\n## 2. Simple Linear Regression (One Predictor)\n\nLet\u0027s predict \u0060price\u0060 based on \u0060carat\u0060.\n\n### Step 2.1: Fit the Model\n\n\u0060\u0060\u0060R\n# Fit a linear model\nmodel_simple \u003C- lm(price ~ carat, data = diamonds_sub)\nsummary(model_simple)\n\u0060\u0060\u0060\n\n### Step 2.2: Generate Predictions and Confidence Intervals\n\nThis is crucial. We need to create a \u0060newdata\u0060 data frame that covers the range of our \u0060carat\u0060 predictor, and then use \u0060predict()\u0060 with \u0060interval = \u0022confidence\u0022\u0060.\n\n\u0060\u0060\u0060R\n# Create a sequence of \u0027carat\u0027 values for prediction\n# This ensures a smooth line and ribbon\nnewdata_simple \u003C- tibble(\n  carat = seq(min(diamonds_sub$carat), max(diamonds_sub$carat), length.out = 100)\n)\n\n# Get predictions with confidence intervals\npredictions_simple \u003C- predict(model_simple, newdata = newdata_simple, interval = \u0022confidence\u0022) %\u003E%\n  as_tibble() %\u003E%\n  bind_cols(newdata_simple) # Add the original \u0027carat\u0027 column back\n\nhead(predictions_simple)\n\u0060\u0060\u0060\n\n\u0060\u0060\u0060\n# A tibble: 6 x 4\n    fit    lwr    upr carat\n  \u003Cdbl\u003E  \u003Cdbl\u003E  \u003Cdbl\u003E \u003Cdbl\u003E\n1 -1978. -2043. -1913. 0.2  \n2 -1763. -1815. -1711. 0.218\n3 -1549. -1591. -1507. 0.235\n4 -1334. -1367. -1302. 0.253\n5 -1120. -1143. -1096. 0.271\n6   -905.  -920.  -890. 0.288\n\u0060\u0060\u0060\n*   \u0060fit\u0060: The predicted mean value.\n*   \u0060lwr\u0060: Lower bound of the confidence interval.\n*   \u0060upr\u0060: Upper bound of the confidence interval.\n\n### Step 2.3: Plot with \u0060ggplot2\u0060\n\n\u0060\u0060\u0060R\nplot_simple \u003C- ggplot(diamonds_sub, aes(x = carat, y = price)) \u002B\n  geom_point(alpha = 0.2, size = 0.8) \u002B # Raw data points\n  geom_line(data = predictions_simple, aes(y = fit), color = \u0022steelblue\u0022, size = 1) \u002B # Prediction line\n  geom_ribbon(data = predictions_simple, aes(ymin = lwr, ymax = upr), fill = \u0022steelblue\u0022, alpha = 0.3) \u002B # Confidence interval\n  labs(\n    title = \u0022Diamond Price Prediction by Carat\u0022,\n    subtitle = \u0022Simple Linear Regression with 95% Confidence Interval\u0022,\n    x = \u0022Carat Weight\u0022,\n    y = \u0022Price (USD)\u0022\n  ) \u002B\n  theme_minimal() \u002B # A clean theme\n  theme(plot.title = element_text(hjust = 0.5), # Center title\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(plot_simple)\n\u0060\u0060\u0060\n\n**Understanding \u0060geom_ribbon()\u0060:**\n*   \u0060geom_ribbon()\u0060 draws a shaded area.\n*   We map \u0060ymin\u0060 to the lower bound (\u0060lwr\u0060) and \u0060ymax\u0060 to the upper bound (\u0060upr\u0060) of our confidence interval.\n*   \u0060fill\u0060 sets the color of the ribbon, and \u0060alpha\u0060 controls its transparency.\n\n---\n\n## 3. Linear Regression with a Categorical Variable\n\nLet\u0027s see how \u0060cut\u0060 quality affects the \u0060price\u0060 vs \u0060carat\u0060 relationship. We\u0027ll fit a model with an interaction term.\n\n### Step 3.1: Fit the Model (with interaction)\n\n\u0060\u0060\u0060R\n# Fit a model including \u0027cut\u0027 as a categorical variable and an interaction\nmodel_interaction \u003C- lm(price ~ carat * cut, data = diamonds_sub)\nsummary(model_interaction)\n\u0060\u0060\u0060\n\n### Step 3.2: Generate Predictions and Confidence Intervals (grouped)\n\nThis time, \u0060newdata\u0060 needs to include all levels of \u0060cut\u0060 and a sequence of \u0060carat\u0060 values for each. \u0060expand_grid()\u0060 is perfect for this.\n\n\u0060\u0060\u0060R\n# Create new data for prediction, covering all combinations of \u0027carat\u0027 and \u0027cut\u0027\nnewdata_interaction \u003C- expand_grid(\n  carat = seq(min(diamonds_sub$carat), max(diamonds_sub$carat), length.out = 100),\n  cut = levels(diamonds_sub$cut) # Use all levels of the factor\n)\n\n# Get predictions with confidence intervals for each group\npredictions_interaction \u003C- predict(model_interaction, newdata = newdata_interaction, interval = \u0022confidence\u0022) %\u003E%\n  as_tibble() %\u003E%\n  bind_cols(newdata_interaction) # Add the original columns back\n\nhead(predictions_interaction)\n\u0060\u0060\u0060\n\n### Step 3.3: Plot with \u0060ggplot2\u0060 (with \u0060color\u0060 and \u0060facet_wrap\u0060)\n\n\u0060\u0060\u0060R\nplot_interaction \u003C- ggplot(diamonds_sub, aes(x = carat, y = price, color = cut)) \u002B\n  geom_point(alpha = 0.1, size = 0.5, aes(color = cut)) \u002B # Raw data, colored by cut\n  geom_line(data = predictions_interaction, aes(y = fit, color = cut), size = 1) \u002B # Prediction lines\n  geom_ribbon(data = predictions_interaction, aes(ymin = lwr, ymax = upr, fill = cut), alpha = 0.2, linetype = 0) \u002B # Confidence intervals, no border\n  labs(\n    title = \u0022Diamond Price Prediction by Carat and Cut\u0022,\n    subtitle = \u0022Linear Regression with Interaction Term (95% Confidence Interval)\u0022,\n    x = \u0022Carat Weight\u0022,\n    y = \u0022Price (USD)\u0022,\n    color = \u0022Cut Quality\u0022,\n    fill = \u0022Cut Quality\u0022\n  ) \u002B\n  scale_color_brewer(palette = \u0022Dark2\u0022) \u002B # Use a colorblind-friendly palette\n  scale_fill_brewer(palette = \u0022Dark2\u0022) \u002B  # Match fill palette\n  theme_minimal() \u002B\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        legend.position = \u0022bottom\u0022)\n\nprint(plot_interaction)\n\n# You can also use facet_wrap() to separate the plots by cut quality\nplot_facet \u003C- ggplot(diamonds_sub, aes(x = carat, y = price)) \u002B\n  geom_point(alpha = 0.1, size = 0.5) \u002B\n  geom_line(data = predictions_interaction, aes(y = fit), color = \u0022steelblue\u0022, size = 1) \u002B\n  geom_ribbon(data = predictions_interaction, aes(ymin = lwr, ymax = upr), fill = \u0022steelblue\u0022, alpha = 0.3, linetype = 0) \u002B\n  facet_wrap(~ cut, scales = \u0022free_y\u0022) \u002B # Separate plots by \u0027cut\u0027, allow y-axis to vary\n  labs(\n    title = \u0022Diamond Price Prediction by Carat, Faceted by Cut\u0022,\n    subtitle = \u0022Linear Regression with Interaction Term (95% Confidence Interval)\u0022,\n    x = \u0022Carat Weight\u0022,\n    y = \u0022Price (USD)\u0022\n  ) \u002B\n  theme_bw() \u002B # Another clean theme\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\nprint(plot_facet)\n\u0060\u0060\u0060\n\n---\n\n## 4. Generalizing with \u0060broom::augment()\u0060 for Cleaner Workflow (Recommended!)\n\nThe \u0060broom\u0060 package offers a much cleaner way to get predictions and CIs, especially for more complex models or GLMs. The \u0060augment()\u0060 function adds model diagnostics (including \u0060.fitted\u0060, \u0060.se.fit\u0060, etc.) to your original data.\n\nFor GLMs, \u0060predict(type = \u0022response\u0022)\u0060 is often necessary to get predictions on the original response scale. \u0060augment()\u0060 handles this elegantly.\n\nLet\u0027s demonstrate with a slightly more complex GLM for \u0060price\u0060 (e.g., \u0060gamma\u0060 family due to skewed price distribution).\n\n### Step 4.1: Fit a GLM\n\n\u0060\u0060\u0060R\n# Fit a Gamma GLM (often good for positive, skewed continuous data like price)\nmodel_glm \u003C- glm(price ~ carat * cut \u002B depth, data = diamonds_sub, family = Gamma(link = \u0022log\u0022))\nsummary(model_glm)\n\u0060\u0060\u0060\n\n### Step 4.2: Generate Predictions and Confidence Intervals with \u0060augment()\u0060\n\nThis is where \u0060augment()\u0060 shines. It can automatically add \u0060.fitted\u0060 and \u0060.se.fit\u0060 (standard error of the fit) which you can then use to calculate CIs, or even directly estimate \u0060conf.int = TRUE\u0060 on the response scale if you have \u0060type.predict = \u0022response\u0022\u0060.\n\nHowever, for a completely *new* sequence of data (like we did with \u0060newdata\u0060), \u0060predict()\u0060 is still the primary function. \u0060augment()\u0060 is best when you want to see how the model fits the *original* data.\n\nLet\u0027s combine the best of both worlds: use \u0060expand_grid\u0060 for \u0060newdata\u0060 and then \u0060predict\u0060 (with \u0060type = \u0022response\u0022\u0060) and manually calculate CIs for GLMs, as \u0060interval = \u0022confidence\u0022\u0060 is not directly supported for GLMs on the response scale.\n\n\u0060\u0060\u0060R\n# Create new data for prediction, covering all combinations\nnewdata_glm \u003C- expand_grid(\n  carat = seq(min(diamonds_sub$carat), max(diamonds_sub$carat), length.out = 100),\n  cut = levels(diamonds_sub$cut),\n  depth = mean(diamonds_sub$depth) # Hold \u0027depth\u0027 constant at its mean\n)\n\n# Get predictions (on the response scale) and standard errors\npredictions_glm_raw \u003C- predict(model_glm, newdata = newdata_glm, type = \u0022response\u0022, se.fit = TRUE)\n\n# Calculate 95% confidence intervals manually for GLMs\n# CI = estimate \u002B/- (z-score * SE)\n# For 95% CI, z-score is approx 1.96\nz_score \u003C- qnorm(0.975)\n\npredictions_glm \u003C- newdata_glm %\u003E%\n  mutate(\n    fit = predictions_glm_raw$fit,\n    se = predictions_glm_raw$se.fit,\n    lwr = fit - z_score * se, # Lower bound\n    upr = fit \u002B z_score * se  # Upper bound\n  ) %\u003E%\n  # Ensure bounds don\u0027t go below 0 (for price)\n  mutate(\n    lwr = pmax(0, lwr) # price cannot be negative\n  )\n\nhead(predictions_glm)\n\u0060\u0060\u0060\n\n### Step 4.3: Plot the GLM Predictions\n\n\u0060\u0060\u0060R\nplot_glm \u003C- ggplot(diamonds_sub, aes(x = carat, y = price, color = cut)) \u002B\n  geom_point(alpha = 0.1, size = 0.5) \u002B\n  geom_line(data = predictions_glm, aes(y = fit, color = cut), size = 1) \u002B\n  geom_ribbon(data = predictions_glm, aes(ymin = lwr, ymax = upr, fill = cut), alpha = 0.2, linetype = 0) \u002B\n  labs(\n    title = \u0022Diamond Price Prediction by Carat, Cut, and Depth (GLM)\u0022,\n    subtitle = \u0022Gamma GLM with 95% Confidence Interval (Depth held at mean)\u0022,\n    x = \u0022Carat Weight\u0022,\n    y = \u0022Price (USD)\u0022,\n    color = \u0022Cut Quality\u0022,\n    fill = \u0022Cut Quality\u0022\n  ) \u002B\n  scale_color_brewer(palette = \u0022Set1\u0022) \u002B\n  scale_fill_brewer(palette = \u0022Set1\u0022) \u002B\n  theme_classic() \u002B # Yet another theme\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5),\n        legend.position = \u0022bottom\u0022)\n\nprint(plot_glm)\n\u0060\u0060\u0060\n\n---\n\n## 5. Publication-Quality Enhancements\n\nBeyond the basics, here are tips for making your plots truly publication-ready:\n\n1.  **Themes:**\n    *   \u0060theme_minimal()\u0060: Clean, simple, good default.\n    *   \u0060theme_bw()\u0060: Black and white, often preferred for publications to save ink/focus on data.\n    *   \u0060theme_classic()\u0060: Similar to \u0060theme_bw\u0060 but without gridlines.\n    *   \u0060theme_void()\u0060: For maximum customization.\n    *   You can also define your \u0060theme()\u0060 elements for specific fonts, sizes, etc.\n    \u0060\u0060\u0060R\n    # Example of a custom theme for publication\n    my_pub_theme \u003C- theme_minimal() \u002B\n      theme(\n        text = element_text(family = \u0022serif\u0022, size = 12), # Specific font and size\n        plot.title = element_text(face = \u0022bold\u0022, size = 14, hjust = 0.5),\n        axis.title = element_text(face = \u0022bold\u0022),\n        axis.text = element_text(color = \u0022black\u0022),\n        legend.title = element_text(face = \u0022bold\u0022),\n        panel.grid.major = element_line(linetype = \u0022dotted\u0022, color = \u0022gray80\u0022),\n        panel.grid.minor = element_blank(), # Remove minor grid lines\n        plot.background = element_rect(fill = \u0022white\u0022, color = NA) # Ensure white background\n      )\n\n    plot_glm \u002B my_pub_theme # Apply to any plot\n    \u0060\u0060\u0060\n\n2.  **Color Palettes:**\n    *   \u0060scale_color_brewer()\u0060 and \u0060scale_fill_brewer()\u0060: Use \u0060RColorBrewer\u0060 palettes (e.g., \u0022Dark2\u0022, \u0022Set1\u0022, \u0022Paired\u0022) for distinct, colorblind-friendly colors.\n    *   \u0060scale_color_viridis_d()\u0060/\u0060_c()\u0060: Viridis palettes are perceptually uniform and colorblind-friendly.\n    *   Manually specify colors with \u0060scale_color_manual()\u0060 or \u0060scale_fill_manual()\u0060.\n\n3.  **Labels and Titles:**\n    *   \u0060labs()\u0060 is your friend. Be descriptive, avoid jargon where possible.\n    *   Adjust \u0060plot.title = element_text(hjust = 0.5)\u0060 to center titles.\n\n4.  **Annotations:**\n    *   \u0060annotate()\u0060: Add text, segments, rectangles, etc., at specific coordinates.\n    *   \u0060geom_text()\u0060 / \u0060geom_label()\u0060: Add labels from your data.\n\n5.  **Line Types, Sizes, Alpha:**\n    *   \u0060size\u0060: Controls thickness of lines/points.\n    *   \u0060alpha\u0060: Controls transparency, useful for dense scatter plots or overlapping ribbons.\n    *   \u0060linetype\u0060: For different lines if you don\u0027t want to rely solely on color.\n\n6.  **Saving Plots:**\n    *   \u0060ggsave()\u0060 allows you to save your plot in various formats (PNG, JPG, PDF, SVG) with specified dimensions and resolution.\n    \u0060\u0060\u0060R\n    ggsave(\u0022diamond_price_prediction.png\u0022, plot_glm, width = 8, height = 6, dpi = 300)\n    ggsave(\u0022diamond_price_prediction.pdf\u0022, plot_glm, width = 8, height = 6) # Vector graphics for best quality\n    \u0060\u0060\u0060\n    *   \u0060dpi = 300\u0060 or \u0060600\u0060 is standard for print publications.\n\n---\n\nThis guide provides a robust framework for visualizing your regression model predictions and confidence intervals using \u0060ggplot2\u0060. Remember to always tailor your plots to the specific story your data and model are telling!", "Grok": "I\u0027ll guide you through creating publication-quality plots for regression model predictions and confidence intervals using ggplot2 in R. Here\u0027s a comprehensive step-by-step approach:\n\n## 1. Basic Setup and Data Preparation\n\nFirst, load the required libraries and prepare your model:\n\n\u0060\u0060\u0060r\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(broom)\nlibrary(gridExtra)  # For combining plots\n\n# Example: Fit a linear regression model\n# Replace with your actual model\ndata(mtcars)\nmodel \u003C- lm(mpg ~ wt \u002B hp \u002B qsec, data = mtcars)\n\n# Create prediction data for smooth curves\npred_data \u003C- data.frame(\n  wt = seq(min(mtcars$wt), max(mtcars$wt), length.out = 100),\n  hp = mean(mtcars$hp),\n  qsec = mean(mtcars$qsec)\n)\n\u0060\u0060\u0060\n\n## 2. Generate Predictions with Confidence Intervals\n\n\u0060\u0060\u0060r\n# Get predictions with confidence intervals\npredictions \u003C- predict(model, \n                      newdata = pred_data, \n                      interval = \u0022confidence\u0022, \n                      level = 0.95) %\u003E%\n  as.data.frame() %\u003E%\n  mutate(wt = pred_data$wt)\n\n# For prediction intervals (individual predictions):\npred_intervals \u003C- predict(model, \n                         newdata = pred_data, \n                         interval = \u0022prediction\u0022, \n                         level = 0.95) %\u003E%\n  as.data.frame() %\u003E%\n  mutate(wt = pred_data$wt)\n\u0060\u0060\u0060\n\n## 3. Basic Plot with Confidence Intervals\n\n\u0060\u0060\u0060r\n# Create the main plot\np1 \u003C- ggplot(mtcars, aes(x = wt, y = mpg)) \u002B\n  geom_point(aes(color = factor(cyl)), \n             size = 2.5, alpha = 0.7) \u002B\n  geom_ribbon(data = predictions, \n              aes(x = wt, ymin = lwr, ymax = upr, \n                  y = fit), \n              fill = \u0022steelblue\u0022, alpha = 0.3, \n              inherit.aes = FALSE) \u002B\n  geom_line(data = predictions, \n            aes(x = wt, y = fit), \n            color = \u0022steelblue\u0022, size = 1) \u002B\n  labs(title = \u0022Regression Model with 95% Confidence Intervals\u0022,\n       x = \u0022Weight (1000 lbs)\u0022,\n       y = \u0022Miles per Gallon\u0022,\n       color = \u0022Cylinders\u0022) \u002B\n  theme_pubr() \u002B  # Use publication theme\n  theme(legend.position = \u0022bottom\u0022,\n        plot.title = element_text(hjust = 0.5, size = 14, face = \u0022bold\u0022))\n\nprint(p1)\n\u0060\u0060\u0060\n\n## 4. Advanced Publication-Quality Plot\n\n\u0060\u0060\u0060r\n# Enhanced version with publication quality\np2 \u003C- ggplot(mtcars, aes(x = wt, y = mpg)) \u002B\n  # Add points with refined styling\n  geom_point(aes(color = factor(cyl)), \n             size = 3, alpha = 0.8, \n             shape = 16) \u002B\n  \n  # Confidence interval ribbon\n  geom_ribbon(data = predictions, \n              aes(x = wt, ymin = lwr, ymax = upr), \n              fill = \u0022#2E86AB\u0022, alpha = 0.25, \n              color = NA) \u002B\n  \n  # Predicted line\n  geom_line(data = predictions, \n            aes(x = wt, y = fit), \n            color = \u0022#2E86AB\u0022, size = 1.2) \u002B\n  \n  # Optional: Prediction intervals (wider band)\n  geom_ribbon(data = pred_intervals, \n              aes(x = wt, ymin = lwr, ymax = upr), \n              fill = \u0022#A23B72\u0022, alpha = 0.15, \n              color = NA, linetype = \u0022dashed\u0022) \u002B\n  \n  # Facets for different cylinder counts (if relevant)\n  facet_wrap(~ factor(cyl), scales = \u0022free_y\u0022, ncol = 2) \u002B\n  \n  scale_color_manual(values = c(\u00224\u0022 = \u0022#F18F01\u0022, \n                               \u00226\u0022 = \u0022#C73E1D\u0022, \n                               \u00228\u0022 = \u0022#2E86AB\u0022)) \u002B\n  \n  labs(title = \u0022MPG vs Weight: Regression with Confidence and Prediction Intervals\u0022,\n       subtitle = \u0022Fitted model: mpg ~ wt \u002B hp \u002B qsec\u0022,\n       x = \u0022Weight (1000 lbs)\u0022,\n       y = \u0022Miles per Gallon (MPG)\u0022,\n       color = \u0022Cylinders\u0022,\n       caption = \u0022Data: mtcars | 95% confidence and prediction intervals\u0022) \u002B\n  \n  # Publication-quality theme\n  theme_classic() \u002B\n  theme(\n    # Title and labels\n    plot.title = element_text(size = 16, face = \u0022bold\u0022, hjust = 0.5),\n    plot.subtitle = element_text(size = 12, color = \u0022grey50\u0022, hjust = 0.5),\n    plot.caption = element_text(size = 10, color = \u0022grey70\u0022, hjust = 1),\n    \n    # Axis titles and text\n    axis.title = element_text(size = 12, face = \u0022bold\u0022),\n    axis.text = element_text(size = 10),\n    \n    # Legend\n    legend.title = element_text(size = 11, face = \u0022bold\u0022),\n    legend.text = element_text(size = 10),\n    legend.position = \u0022bottom\u0022,\n    legend.box = \u0022horizontal\u0022,\n    \n    # Facet labels\n    strip.background = element_rect(fill = \u0022grey95\u0022, color = \u0022grey80\u0022),\n    strip.text = element_text(size = 11, face = \u0022bold\u0022)\n  ) \u002B\n  \n  # Add R\u00B2 and other statistics as annotation\n  annotate(\u0022text\u0022, x = Inf, y = Inf, \n           label = paste(\u0022R\u00B2 =\u0022, round(summary(model)$r.squared, 3)),\n           hjust = 1.1, vjust = 1.1, \n           size = 4, fontface = \u0022bold\u0022)\n\nprint(p2)\n\u0060\u0060\u0060\n\n## 5. Multiple Variable Plots (Partial Dependence)\n\nFor models with multiple predictors, create plots for each:\n\n\u0060\u0060\u0060r\n# Function to create plots for each predictor\ncreate_reg_plot \u003C- function(model, data, predictor_var) {\n  # Create prediction data for this variable\n  pred_range \u003C- seq(min(data[[predictor_var]], na.rm = TRUE),\n                   max(data[[predictor_var]], na.rm = TRUE),\n                   length.out = 100)\n  \n  pred_data \u003C- data %\u003E%\n    select(-all_of(predictor_var)) %\u003E%\n    slice(1) %\u003E%\n    mutate(!!predictor_var := pred_range)\n  \n  # Get predictions\n  preds \u003C- predict(model, newdata = pred_data, interval = \u0022confidence\u0022) %\u003E%\n    as.data.frame() %\u003E%\n    mutate(!!predictor_var := pred_range)\n  \n  # Create plot\n  ggplot(data, aes_string(x = predictor_var, y = as.character(formula(model)[[2]]))) \u002B\n    geom_point(alpha = 0.6, size = 2) \u002B\n    geom_ribbon(data = preds, \n                aes_string(x = predictor_var, ymin = \u0022lwr\u0022, ymax = \u0022upr\u0022, y = \u0022fit\u0022),\n                fill = \u0022#2E86AB\u0022, alpha = 0.25) \u002B\n    geom_line(data = preds, \n              aes_string(x = predictor_var, y = \u0022fit\u0022), \n              color = \u0022#2E86AB\u0022, size = 1) \u002B\n    labs(title = paste(\u0022Effect of\u0022, predictor_var),\n         x = predictor_var,\n         y = as.character(formula(model)[[2]])) \u002B\n    theme_pubr() \u002B\n    theme(plot.title = element_text(hjust = 0.5))\n}\n\n# Create plots for each predictor\npredictors \u003C- c(\u0022wt\u0022, \u0022hp\u0022, \u0022qsec\u0022)\nplots \u003C- lapply(predictors, function(p) create_reg_plot(model, mtcars, p))\n\n# Combine plots\ncombined_plot \u003C- grid.arrange(grobs = plots, ncol = 2)\n\u0060\u0060\u0060\n\n## 6. Saving Publication-Quality Figures\n\n\u0060\u0060\u0060r\n# Save with high resolution\nggsave(\u0022regression_plot.png\u0022, plot = p2, \n       width = 10, height = 8, dpi = 300, \n       bg = \u0022white\u0022)\n\n# For vector graphics (PDF/EPS for publications)\nggsave(\u0022regression_plot.pdf\u0022, plot = p2, \n       width = 10, height = 8, device = \u0022pdf\u0022)\n\n# For presentations\nggsave(\u0022regression_plot.pptx\u0022, plot = p2, \n       width = 12, height = 9, \n       device = \u0022win.metafile\u0022)  # On Windows\n\n# High-quality TIFF for journals\nggsave(\u0022regression_plot.tiff\u0022, plot = p2, \n       width = 6.5, height = 5, dpi = 600, \n       compression = \u0022lzw\u0022, bg = \u0022white\u0022)\n\u0060\u0060\u0060\n\n## 7. Custom Themes for Publications\n\n\u0060\u0060\u0060r\n# Create a custom publication theme\ntheme_publication \u003C- function(base_size = 11, base_family = \u0022\u0022) {\n  theme_classic(base_size = base_size, base_family = base_family) %\u002Breplace%\n    theme(\n      # Text elements\n      plot.title = element_text(size = rel(1.2), hjust = 0.5, \n                               face = \u0022bold\u0022, margin = margin(b = 10)),\n      plot.subtitle = element_text(size = rel(1.0), hjust = 0.5, \n                                  margin = margin(b = 8)),\n      plot.caption = element_text(hjust = 1, size = rel(0.8), \n                                 color = \u0022grey60\u0022, margin = margin(t = 10)),\n      \n      # Axis\n      axis.title = element_text(size = rel(1.0), face = \u0022bold\u0022),\n      axis.text ="}' published-date="{DateTime.UtcNow:HH:mm}"
/>

## Analysis

This comparison demonstrates the different approaches each AI model takes when responding to the same prompt. Here are the key differences observed:

### Response Characteristics

**Gemini**: Provides a direct response with 176 sentences. 

**Grok**: Provides a direct response with 76 sentences. 

## Key Takeaways

- Each model brings unique strengths to this type of query
- Response styles vary significantly between models
- Consider your specific use case when choosing between these models

## Try This Comparison Yourself

Want to test these models with your own prompts? Visit [SNEOS.com](https://sneos.com) to compare AI responses side-by-side in real-time.

---

*This comparison was generated using the [SNEOS AI Comparison Tool](https://sneos.com)*
*Published: October 15, 2025 | Models: Gemini, Grok*
