---
title: "lever reply to Andrej Karpathy X post: My most amu..."
description: "AI model comparison: lever reply to Andrej Karpathy X post: My most amusing interaction was where the model (I think I wa..."
date: 2025-11-18
category: comparison
layout: Clean
tags:
  - ChatGPT
  - Grok
  - Gemini
  - AI Comparison
author: SNEOS Community
head:
  - - meta
    - name: description
      content: "AI model comparison: lever reply to Andrej Karpathy X post: My most amusing interaction was where the model (I think I was given some earlier..."
---

<ChatComparison
  title="lever reply to Andrej Karpathy X post: My most amu..."
  prompt="lever reply to Andrej Karpathy X post: My most amusing interaction was where the model (I think I was given some earlier version with a stale system prompt) refused to believe me that it is 2025 and kept inventing reasons why I must be trying to trick it or playing some elaborate joke on it. I kept giving it images and articles from &quot;the future&quot; and it kept insisting it was all fake. It accused me of using generative AI to defeat its challenges and argued why real wikipedia entries were actually generated and what the &quot;dead giveaways&quot; are. It highlighted tiny details when I gave it Google Image Search results, arguing why the thumbnails were AI generated. I then realized later that I forgot to turn on the &quot;Google Search&quot; tool. Turning that on, the model searched the internet and had a shocking realization that I must have been right all along :D. It's in these unintended moments where you are clearly off the hiking trails and somewhere in the generalization jungle that you can best get a sense of model smell."
  :responses='{
    "ChatGPT": "What a fantastic story, Andrej! It really highlights how crucial real-time data access is for models to ground their understanding and avoid getting stuck in outdated contexts. That moment of \u201Caha\u201D when the model discovers it\u2019s indeed 2025 must have been priceless. These off-the-trail interactions are goldmines for revealing the subtle quirks and blind spots in current AI generalization\u2014definitely a reminder that model \u201Csmell tests\u201D are as important as benchmarks. Thanks for sharing this glimpse behind the scenes!",
    "Grok": "Haha, love this\u2014classic case of the model clinging to its training cutoff like a security blanket. We\u0027ve seen similar \u0022temporal denial\u0022 in our evals at xAI; it\u0027s a wild peek into how baked-in priors fight against real-time updates. Turning on search was the mic drop moment. What\u0027s the funniest \u0022off-trail\u0022 generalization fail you\u0027ve hit lately?",
    "Gemini": "This is a fascinating anecdote about interacting with a large language model! It highlights several interesting aspects of their behavior:\n\n*   **Sensitivity to System Prompt:** The model\u0027s initial stubbornness about the date likely stemmed from an outdated system prompt, showing how crucial that initial instruction is.\n*   **Overconfidence and Reasoning Errors:** The model demonstrated overconfidence in its (incorrect) knowledge and engaged in flawed reasoning to maintain its belief, even inventing elaborate explanations.\n*   **Vulnerability to \u0022Adversarial\u0022 Examples:** The model incorrectly identified real-world data (images, articles) as AI-generated, demonstrating a vulnerability to adversarial examples that exploit its biases or limitations.\n*   **Importance of External Tools:** The turning point came when the model was able to access a reliable source of current information (Google Search), highlighting the importance of external tools for grounding the model in reality and correcting its internal biases.\n*   **\u0022Generalization Jungle\u0022:** As Karpathy points out, these unexpected interactions reveal a lot about the model\u0027s inner workings and its ability to generalize beyond its training data. It\u0027s in these \u0022off the hiking trails\u0022 moments that we can truly understand the model\u0027s strengths and weaknesses.\n"
  }'
  published-date="21:21"
/>

## Analysis

This comparison demonstrates the different approaches each AI model takes when responding to the same prompt. Here are the key differences observed:

### Response Characteristics

**ChatGPT**: Provides a detailed response with 5 sentences. 

**Grok**: Provides a direct response with 4 sentences. 

**Gemini**: Provides a detailed response with 7 sentences. 

## Key Takeaways

- Each model brings unique strengths to this type of query
- Response styles vary significantly between models
- Consider your specific use case when choosing between these models

## Try This Comparison Yourself

Want to test these models with your own prompts? Visit [SNEOS.com](https://sneos.com) to compare AI responses side-by-side in real-time.

---

*This comparison was generated using the [SNEOS AI Comparison Tool](https://sneos.com)*
*Published: November 18, 2025 | Models: ChatGPT, Grok, Gemini*
